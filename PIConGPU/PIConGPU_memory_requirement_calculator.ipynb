{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This file can roughly calculate the expected memory consumption of PIConGPU per GPU if nothing moves.\n",
    "\n",
    "Copyright 2017-2018 PIConGPU contributors\n",
    "Authors: Marco Garten\n",
    "License: LGPLv3+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory requirement calculator for PIConGPU <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "from scipy import constants as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Override Matplotlib Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OVERWRITE DEFAULT PLOTTING PARAMETERS\n",
    "params = {\n",
    "    'font.size' : 20,\n",
    "    'lines.linewidth' : 3,\n",
    "    'legend.fontsize' : 20,\n",
    "    'legend.frameon' : False,\n",
    "    'legend.numpoints': 1,\n",
    "    'xtick.labelsize' : 20,\n",
    "    'ytick.labelsize' : 20,\n",
    "    'figure.figsize': [12,8],\n",
    "    'axes.labelsize' : 20\n",
    "}\n",
    "mpl.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mem_req_by_fields(Lx,Ly,Lz,FieldTMPSlots = 1,particle_shape_order=2,sim_dim=3):\n",
    "    \"\"\" Memory reserved for fields on each GPU\n",
    "    \n",
    "        Returns:\n",
    "            req_mem required memory {unit: bytes}\n",
    "    \"\"\"\n",
    "    # guard size in super cells in x, y, z\n",
    "    guard_size_SC = np.array([1, 1, 1])\n",
    "    # super cell size in cells in x, y, z\n",
    "    SC_size = np.array([8,8,4])\n",
    "    \n",
    "    pso = particle_shape_order\n",
    "    \n",
    "    if sim_dim == 2:\n",
    "        local_cells =     (Lx + SC_size[0] * 2 * guard_size_SC[0]) \\\n",
    "                        * (Ly + SC_size[1] * 2 * guard_size_SC[1])\n",
    "    \n",
    "        # cells around core-border region due to particle shape\n",
    "        double_buffer_cells = (Lx + pso) * (Ly + pso) \\\n",
    "                            -  Lx        *  Ly\n",
    "    elif sim_dim == 3: \n",
    "        local_cells =     (Lx + SC_size[0] * 2 * guard_size_SC[0]) \\\n",
    "                        * (Ly + SC_size[1] * 2 * guard_size_SC[1]) \\\n",
    "                        * (Lz + SC_size[2] * 2 * guard_size_SC[2])\n",
    "    \n",
    "        # cells around core-border region due to particle shape\n",
    "        double_buffer_cells = (Lx + 2 * pso) * (Ly + 2 * pso) * (Lz + 2 * pso) \\\n",
    "                            -  Lx        *  Ly        *  Lz\n",
    "    else:\n",
    "        raise ValueError(\"PIConGPU only runs in either 2D or 3D: \",sim_dim,\" =/= {2, 3}\")\n",
    "    \n",
    "    # size of a data entry in bytes\n",
    "    data_size = np.float32().itemsize\n",
    "    # number of fields: 3 * 3 = x,y,z for E,B,J\n",
    "    num_fields = 3 * 3 + FieldTMPSlots\n",
    "    # double buffer memory\n",
    "    double_buffer_mem = double_buffer_cells * num_fields * data_size\n",
    "    req_mem = data_size * num_fields * local_cells + double_buffer_mem\n",
    "    return req_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mem_req_by_particles(\n",
    "    Lx,\n",
    "    Ly,\n",
    "    Lz,\n",
    "    num_additional_attributes = 0,\n",
    "    particles_per_cell = 2\n",
    "):\n",
    "    \"\"\" Memory reserved for all particles of a species on a GPU.\n",
    "        We currently neglect the constant species memory.\n",
    "        \n",
    "        Params:\n",
    "        \n",
    "            num_additional_attributes : number of additional attributes like e.g. `boundElectrons`\n",
    "            \n",
    "        Returns:\n",
    "            req_mem required memory {unit: bytes} per GPU and species\n",
    "    \"\"\"\n",
    "    # memory required by the standard particle attributes\n",
    "    standard_attribute_mem = np.array([\n",
    "        3 * 4, # momentum\n",
    "        3 * 4, # position\n",
    "        1 * 8, # multimask\n",
    "        1 * 8, # cell index in supercell {lcellId_t}\n",
    "        1 * 8  # weighting\n",
    "    ])\n",
    "    \n",
    "    additional_mem = num_additional_attributes * 4 # we assume 4 bytes here - check if that's really the case\n",
    "    \n",
    "    local_cells = Lx * Ly * Lz\n",
    "    \n",
    "    req_mem = local_cells * (np.sum(standard_attribute_mem) + additional_mem) * particles_per_cell\n",
    "    \n",
    "    return req_mem\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNG states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mem_req_by_rng(Lx,Ly,Lz):\n",
    "    \"\"\" Memory reserved for the random number generator state on each GPU.\n",
    "        The RNG we use is: MRG32ka\n",
    "    \n",
    "        Returns:\n",
    "            req_mem required memory {unit: bytes} per GPU\n",
    "    \"\"\"\n",
    "    req_mem_per_cell = 6 * 8 # bytes\n",
    "    local_cells = Lx * Ly * Lz\n",
    "    req_mem = req_mem_per_cell * local_cells\n",
    "    return req_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cu 30nm foil setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `20 x 3 x 40` case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory requirement per GPU for fields:  3222.39575195 MB\n",
      "Memory requirement per GPU and species:\n",
      "e:  768.1875 MB\n",
      "H:  17.265625 MB\n",
      "C:  8.6328125 MB\n",
      "Cu:  29.3515625 MB\n",
      "Memory requirement per GPU for RNG states:  2970.75 MB\n",
      "Sum of required GPU memory:  7016.58325195 MB\n"
     ]
    }
   ],
   "source": [
    "Lx = 272\n",
    "Ly = 1864\n",
    "Lz = 128\n",
    "\n",
    "target_x = Lx\n",
    "target_y = 17\n",
    "target_z = Lz\n",
    "\n",
    "# field memory per GPU\n",
    "field_gpu = mem_req_by_fields(Lx, Ly, Lz, FieldTMPSlots=2)\n",
    "print(\"Memory requirement per GPU for fields: \",field_gpu / (1024 * 1024),\"MB\")\n",
    "# particle memory per GPU - only the target area contributes here\n",
    "e_gpu  = mem_req_by_particles(target_x, target_y, target_z, \n",
    "                              num_additional_attributes=0, \n",
    "                              particles_per_cell=26)         \\\n",
    "       + mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=0, \n",
    "                              particles_per_cell=10)         \\\n",
    "       + mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=0, \n",
    "                              particles_per_cell=(5 * 6))\n",
    "H_gpu  = mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=1, \n",
    "                              particles_per_cell=10)\n",
    "C_gpu  = mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=1, \n",
    "                              particles_per_cell=5)\n",
    "Cu_gpu = mem_req_by_particles(target_x, target_y, target_z, \n",
    "                              num_additional_attributes=1, \n",
    "                              particles_per_cell=1)\n",
    "print(\"Memory requirement per GPU and species:\")\n",
    "print(\"e: \", e_gpu / (1024 * 1024),\"MB\")\n",
    "print(\"H: \", H_gpu / (1024 * 1024),\"MB\")\n",
    "print(\"C: \", C_gpu / (1024 * 1024),\"MB\")\n",
    "print(\"Cu: \",Cu_gpu / (1024 * 1024),\"MB\")\n",
    "rng_gpu = mem_req_by_rng(Lx, Ly, Lz)\n",
    "print(\"Memory requirement per GPU for RNG states: \",rng_gpu / (1024 * 1024),\"MB\")\n",
    "\n",
    "mem_sum = field_gpu + e_gpu + H_gpu + C_gpu + Cu_gpu + rng_gpu\n",
    "print(\"Sum of required GPU memory: \",mem_sum / (1024 * 1024),\"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Test with `20 x 3` GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My idea is now to use the same setup just reduced by the number of GPUs in the third direction and also just in 2D. \n",
    "But that way I can make an estimate for the full case without changing the domain decomposition again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory requirement per GPU for fields:  22.8991546631 MB\n",
      "Memory requirement per GPU and species:\n",
      "e:  6.00146484375 MB\n",
      "H:  0.134887695312 MB\n",
      "C:  0.0674438476562 MB\n",
      "Cu:  0.229309082031 MB\n",
      "Memory requirement per GPU for RNG states:  23.208984375 MB\n",
      "Sum of required GPU memory:  52.5412445068 MB\n"
     ]
    }
   ],
   "source": [
    "Lx = 272\n",
    "Ly = 1864\n",
    "Lz = 1\n",
    "\n",
    "target_x = Lx\n",
    "target_y = 17\n",
    "target_z = Lz\n",
    "\n",
    "# field memory per GPU\n",
    "field_gpu = mem_req_by_fields(Lx, Ly, Lz, FieldTMPSlots=2,sim_dim=2)\n",
    "print(\"Memory requirement per GPU for fields: \",field_gpu / (1024 * 1024),\"MB\")\n",
    "# particle memory per GPU - only the target area contributes here\n",
    "e_gpu  = mem_req_by_particles(target_x, target_y, target_z, \n",
    "                              num_additional_attributes=0, \n",
    "                              particles_per_cell=26)         \\\n",
    "       + mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=0, \n",
    "                              particles_per_cell=10)         \\\n",
    "       + mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=0, \n",
    "                              particles_per_cell=(5 * 6))\n",
    "H_gpu  = mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=1, \n",
    "                              particles_per_cell=10)\n",
    "C_gpu  = mem_req_by_particles(target_x, 1, target_z, \n",
    "                              num_additional_attributes=1, \n",
    "                              particles_per_cell=5)\n",
    "Cu_gpu = mem_req_by_particles(target_x, target_y, target_z, \n",
    "                              num_additional_attributes=1, \n",
    "                              particles_per_cell=1)\n",
    "print(\"Memory requirement per GPU and species:\")\n",
    "print(\"e: \", e_gpu / (1024 * 1024),\"MB\")\n",
    "print(\"H: \", H_gpu / (1024 * 1024),\"MB\")\n",
    "print(\"C: \", C_gpu / (1024 * 1024),\"MB\")\n",
    "print(\"Cu: \",Cu_gpu / (1024 * 1024),\"MB\")\n",
    "rng_gpu = mem_req_by_rng(Lx, Ly, Lz)\n",
    "print(\"Memory requirement per GPU for RNG states: \",rng_gpu / (1024 * 1024),\"MB\")\n",
    "\n",
    "mem_sum = field_gpu + e_gpu + H_gpu + C_gpu + Cu_gpu + rng_gpu\n",
    "print(\"Sum of required GPU memory: \",mem_sum / (1024 * 1024),\"MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
